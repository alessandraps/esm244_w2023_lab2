---
title: "ESM 244 Lab 2"
author: "Alessandra Puig-Santana"
date: "2023-01-19"
output: html_document
---

```{r setup, echo = TRUE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(tidyverse)
library(palmerpenguins)
library(AICcmodavg)
library(equatiomatic)
```

# Predicting Penguin mass

```{r}
penguins_clean <- penguins %>%
  drop_na() %>%
  rename(mass = body_mass_g,
         bill_l = bill_length_mm,
         bill_d = bill_depth_mm,
         flip_l = flipper_length_mm)

mdl1 <- lm(mass ~ bill_l + bill_d + flip_l + species + sex + island, 
           data = penguins_clean) #mass as a function of..

mdl1 # calling it out see our model
AIC(mdl1) # seeing the AIC value of this model
```

```{r}
f1 <- mass ~ bill_l + bill_d + flip_l + species + sex + island #formula 1

mdl1 <- lm(f1, data = penguins_clean) # cleans up our model

f2 <- mass ~ bill_l + bill_d + flip_l + species + sex

mdl2 <- lm(f2, data = penguins_clean)

AIC(mdl1, mdl2)

f3 <- mass ~ bill_d + flip_l + species + sex

mdl3 <- lm(f3, data = penguins_clean)

AIC(mdl1, mdl2, mdl3)
BIC(mdl1, mdl2, mdl3)

# If using an uncommon function, you can use the double colon to see what package that it came from
AICcmodavg::AICc(mdl1) #the corrected AIC

aictab(list(mdl1, mdl2, mdl3)) #ranks it in order from best to worst, Delta shows that there is evidence that #1 model is better than the rest
bictab(list(mdl1, mdl2, mdl3))
```


# Compare models using k-fold cross validation 

```{r}
folds <- 10  #we are taking our data set and breaking it out to 10 chunks and will test

fold_vec <- rep(1:folds, length.out = nrow(penguins_clean)) #creating vectors to classify and organize our data

set.seed(42)

penguins_fold <- penguins_clean %>%
  mutate(group = sample(fold_vec, size = n(), replace = FALSE))

table(penguins_fold$group)

test_df <- penguins_fold %>%
  filter(group == 1)
train_df <- penguins_fold %>%
  filter(group !=1)
```

### Create a function

```{r}
calc_mean <- function(x) { #practice function
  m <- sum(x) / length(x)
}
calc_rmse <- function(x, y) {
  rmse <- (x-y)^2 %>%
    mean() %>%
    sqrt() %>%
    return(rmse)
}
```

```{r}
training_mdl1 <- lm(f1, data = train_df)

training_mdl2 <- lm(f2, data = train_df)

training_mdl3 <- lm(f3, data = train_df)

## see how well these predict

predict_test <- test_df %>%
  mutate(model1 = predict(training_mdl1, test_df),
         model2 = predict(training_mdl2, test_df),
         model3 = predict(training_mdl3, test_df))

rmse_predict_test <- predict_test %>%
  summarize(rmse_mdl1 = calc_rmse(model1, mass),
            rmse_mdl2 = calc_rmse(model2, mass),
            rmse_mdl3 = calc_rmse(model3, mass)) # take the predicted mass to subtract by the known mass adn then we will take the square them, then average them, and then square root them to see how far are the predicted values are from the known values. It tells us how well are our predictions. We want to see which one has the lowest value. 
```

# Let's iterate!
```{r}
rmse_df <- data.frame()

# Four each one of these values, we are assigning it i and then going to do something with it. Start the loops, we will be repeating the steps above of the cross validation 

# types of data
## df = data frame 
## sf = simple feature
## r = raster

for(i in 1:folds) {
  ### i <- 1 ### to test
  kfold_test_df <- penguins_fold %>%
    filter(group == i)
  kfold_train_df <- penguins_fold %>%
    filter(group != i) 
  
  kfold_mdl1 <- lm(f1, data = kfold_train_df)
  kfold_mdl2 <- lm(f2, data = kfold_train_df)
  kfold_mdl3 <- lm(f3, data = kfold_train_df)
  
  kfold_pred_df <- kfold_test_df %>%
    mutate(mdl1 = predict(kfold_mdl1, .), # short-hand to to adding the data frame its working on
           mdl2 = predict(kfold_mdl2, .),
           mdl3 = predict(kfold_mdl3, .))
  kfold_rmse_df <- kfold_pred_df %>%
    summarize(rmse_mdl1 = calc_rmse(mdl1, mass),
              rmse_mdl2 = calc_rmse(mdl2, mass),
              rmse_mdl3 = calc_rmse(mdl3, mass),
              test_gp = i)
  rmse_df <- bind_rows(rmse_df, kfold_rmse_df) #binding the empty data frame to our results
}

rmse_df %>%
  summarize(mean_rmse_mdl1 = mean(rmse_mdl1),
            mean_rmse_mdl2 = mean(rmse_mdl2),
            mean_rmse_mdl3 = mean(rmse_mdl3))
```

# Finalize the model
```{r}
final_mdl <- lm(f2, data = penguins_clean)
```

 Our final model:
 `r equatiomatic::extract_eq(final_mdl, wrap = TRUE)`
 
 And with coefficients:
 `r equatiomatic::extract_eq(final_mdl, wrap = TRUE, use_coefs = TRUE)`
